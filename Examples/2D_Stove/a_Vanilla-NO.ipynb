{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f24266",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "\n",
    "This code can execute the following variants of losses:  \n",
    "\n",
    "1. **Variant 1:**  Purely Physics  \n",
    "   $L_{\\theta} = L_{\\text{PDE}}$  \n",
    "   Use $n_{\\text{used}} = 0$  \n",
    "\n",
    "2. **Variant 2:**  Physics + Data  \n",
    "   $L_{\\theta} = L_{\\text{PDE}} + \\Sigma_{i=1}^{n_{\\text{used}}}\\| u_i - \\hat{u}_i \\|_2^2$  \n",
    "   Use $n_{\\text{used}} \\in (0, 500]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224272da",
   "metadata": {
    "papermill": {
     "duration": 0.003533,
     "end_time": "2024-12-29T06:11:57.364931",
     "exception": false,
     "start_time": "2024-12-29T06:11:57.361398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "All the results presented were obtained as follows:\n",
    "1. By estimating the gradients in the physics-informed loss terms using forward mode automatic differentiation (AD).\n",
    "2. The output field values at given grid points were computed in one forward pass of the network using the einsum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1395ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:11:57.371353Z",
     "iopub.status.busy": "2024-12-29T06:11:57.371059Z",
     "iopub.status.idle": "2024-12-29T06:11:59.925720Z",
     "shell.execute_reply": "2024-12-29T06:11:59.925288Z"
    },
    "papermill": {
     "duration": 2.559233,
     "end_time": "2024-12-29T06:11:59.927095",
     "exception": false,
     "start_time": "2024-12-29T06:11:57.367862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.distributions as td\n",
    "import math\n",
    "from sklearn import metrics\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from utils.networks import *\n",
    "from utils.visualizer_misc import *\n",
    "from utils.forward_autodiff import *\n",
    "from utils.misc import *\n",
    "\n",
    "from utils.deeponet_networks_2d import *\n",
    "from utils.misc_stove import *\n",
    "from utils.visualizer_stove import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e21cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:11:59.934215Z",
     "iopub.status.busy": "2024-12-29T06:11:59.933844Z",
     "iopub.status.idle": "2024-12-29T06:11:59.936419Z",
     "shell.execute_reply": "2024-12-29T06:11:59.936088Z"
    },
    "papermill": {
     "duration": 0.006801,
     "end_time": "2024-12-29T06:11:59.937197",
     "exception": false,
     "start_time": "2024-12-29T06:11:59.930396",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Tag this cell with 'parameters'\n",
    "# parameters\n",
    "seed = 0 # Seed number.\n",
    "n_used = 150 # Ensure n_used is a multiple of 10 (as group size is 10) # Number of full training fields used for estimating the data-driven loss term\n",
    "n_iterations = 50000 # Number of iterations.\n",
    "save = True # Save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f9ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:11:59.951710Z",
     "iopub.status.busy": "2024-12-29T06:11:59.951434Z",
     "iopub.status.idle": "2024-12-29T06:11:59.953883Z",
     "shell.execute_reply": "2024-12-29T06:11:59.953574Z"
    },
    "papermill": {
     "duration": 0.006281,
     "end_time": "2024-12-29T06:11:59.954649",
     "exception": false,
     "start_time": "2024-12-29T06:11:59.948368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save == True:\n",
    "    resultdir = os.path.join(os.getcwd(),'results','a_Vanilla-NO','seed='+str(seed)+'_n_used='+str(n_used)) \n",
    "    if not os.path.exists(resultdir):\n",
    "        os.makedirs(resultdir)\n",
    "else:\n",
    "    resultdir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb4cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:11:59.960678Z",
     "iopub.status.busy": "2024-12-29T06:11:59.960396Z",
     "iopub.status.idle": "2024-12-29T06:11:59.963352Z",
     "shell.execute_reply": "2024-12-29T06:11:59.963023Z"
    },
    "papermill": {
     "duration": 0.006809,
     "end_time": "2024-12-29T06:11:59.964105",
     "exception": false,
     "start_time": "2024-12-29T06:11:59.957296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d11f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:11:59.970192Z",
     "iopub.status.busy": "2024-12-29T06:11:59.969930Z",
     "iopub.status.idle": "2024-12-29T06:12:00.115080Z",
     "shell.execute_reply": "2024-12-29T06:12:00.114724Z"
    },
    "papermill": {
     "duration": 0.149044,
     "end_time": "2024-12-29T06:12:00.115840",
     "exception": false,
     "start_time": "2024-12-29T06:11:59.966796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e0b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:00.122100Z",
     "iopub.status.busy": "2024-12-29T06:12:00.121815Z",
     "iopub.status.idle": "2024-12-29T06:12:00.415664Z",
     "shell.execute_reply": "2024-12-29T06:12:00.415279Z"
    },
    "papermill": {
     "duration": 0.297808,
     "end_time": "2024-12-29T06:12:00.416462",
     "exception": false,
     "start_time": "2024-12-29T06:12:00.118654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_np = np.load(os.path.join('..','..','data/2D_Stove/metadata.npz'), allow_pickle=True)\n",
    "metadata = convert_metadata_to_torch(metadata_np, device)\n",
    "for key, value in metadata.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"Shape of {key}: {value.shape}\")\n",
    "        elif isinstance(value, dict):\n",
    "            print(f\"{key} is a dictionary with {len(value)} keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f912b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:00.422889Z",
     "iopub.status.busy": "2024-12-29T06:12:00.422587Z",
     "iopub.status.idle": "2024-12-29T06:12:00.663115Z",
     "shell.execute_reply": "2024-12-29T06:12:00.662741Z"
    },
    "papermill": {
     "duration": 0.244589,
     "end_time": "2024-12-29T06:12:00.663900",
     "exception": false,
     "start_time": "2024-12-29T06:12:00.419311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_span, x_span, y_span = metadata['t_span'], metadata['x_span'], metadata['y_span']\n",
    "\n",
    "nt, nx, ny = len(t_span), len(x_span), len(y_span) # number of discretizations in time, location_x and location_y.\n",
    "print(\"nt =\",nt, \", nx =\",nx, \"ny =\",ny)\n",
    "print(\"Shape of t-span, x-span, and y-span:\",t_span.shape, x_span.shape, y_span.shape)\n",
    "print(\"t-span:\", t_span)\n",
    "print(\"x-span:\", x_span)\n",
    "print(\"y-span:\", y_span)\n",
    "\n",
    "L = 2.         # Simulation domain [-L, L]^2\n",
    "T = 1.         # Simulation time\n",
    "D_value = 1.0  # Diffusion coefficient  \n",
    "\n",
    "grid = torch.vstack((t_span.repeat_interleave(ny*nx), \n",
    "              x_span.flatten().repeat(nt),\n",
    "              y_span.flatten().repeat(nt))).T\n",
    "print(\"Shape of grid:\", grid.shape) # (nt*nx*ny, 3)\n",
    "print(\"grid:\", grid) # time, location_x, location_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4ead1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:00.670605Z",
     "iopub.status.busy": "2024-12-29T06:12:00.670250Z",
     "iopub.status.idle": "2024-12-29T06:12:00.825335Z",
     "shell.execute_reply": "2024-12-29T06:12:00.824987Z"
    },
    "papermill": {
     "duration": 0.159264,
     "end_time": "2024-12-29T06:12:00.826136",
     "exception": false,
     "start_time": "2024-12-29T06:12:00.666872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stove_full_solution_fields_groups_np = np.load(os.path.join('..','..','data/2D_Stove/stove_full_solution_fields.npz'), allow_pickle=True)\n",
    "print(stove_full_solution_fields_groups_np.keys())\n",
    "\n",
    "stove_source_fields_only_groups_np = np.load(os.path.join('..','..','data/2D_Stove/stove_source_fields_only.npz'), allow_pickle=True)\n",
    "print(stove_source_fields_only_groups_np.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998de134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:00.832957Z",
     "iopub.status.busy": "2024-12-29T06:12:00.832729Z",
     "iopub.status.idle": "2024-12-29T06:12:03.365833Z",
     "shell.execute_reply": "2024-12-29T06:12:03.365397Z"
    },
    "papermill": {
     "duration": 2.537432,
     "end_time": "2024-12-29T06:12:03.366735",
     "exception": false,
     "start_time": "2024-12-29T06:12:00.829303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the NumPy groups to Pytorch\n",
    "stove_full_solution_fields_groups = convert_groupdict_to_torch(stove_full_solution_fields_groups_np, device)\n",
    "stove_source_fields_only_groups = convert_groupdict_to_torch(stove_source_fields_only_groups_np, device)\n",
    "\n",
    "# Check the shapes\n",
    "print('stove_full_solution_fields_groups:')\n",
    "check_shapes(stove_full_solution_fields_groups)\n",
    "print(colored('#' * 230, 'green'))\n",
    "\n",
    "print('stove_source_fields_only_groups:')\n",
    "check_shapes(stove_source_fields_only_groups)\n",
    "print(colored('#' * 230, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a174b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.375057Z",
     "iopub.status.busy": "2024-12-29T06:12:03.374887Z",
     "iopub.status.idle": "2024-12-29T06:12:03.379481Z",
     "shell.execute_reply": "2024-12-29T06:12:03.379153Z"
    },
    "papermill": {
     "duration": 0.009234,
     "end_time": "2024-12-29T06:12:03.380335",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.371101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing groups\n",
    "train_group, test_group = split_groups(stove_full_solution_fields_groups, seed, train_size=50, test_size=10)\n",
    "\n",
    "# Print the shapes for verification\n",
    "print(\"Training Group:\")\n",
    "print(colored('#' * 20, 'red'))\n",
    "print_group_shapes(train_group)\n",
    "print(colored('#' * 230, 'green'))\n",
    "print(\"Testing Group:\")\n",
    "print(colored('#' * 20, 'red'))\n",
    "print_group_shapes(test_group)\n",
    "print(colored('#' * 230, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1da6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.387184Z",
     "iopub.status.busy": "2024-12-29T06:12:03.386788Z",
     "iopub.status.idle": "2024-12-29T06:12:03.396525Z",
     "shell.execute_reply": "2024-12-29T06:12:03.396080Z"
    },
    "papermill": {
     "duration": 0.014063,
     "end_time": "2024-12-29T06:12:03.397384",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.383321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = load_and_combine_groups(train_group, 'Train', combine=True, device=device)\n",
    "input_parameters_train = train_data['input_parameters']\n",
    "inputs_train = train_data['input_samples']\n",
    "outputs_train = train_data['output_samples']\n",
    "\n",
    "test_data = load_and_combine_groups(test_group, 'Test', combine=True, device=device)\n",
    "input_parameters_test = test_data['input_parameters']\n",
    "inputs_test = test_data['input_samples']\n",
    "outputs_test = test_data['output_samples']\n",
    "\n",
    "print(colored('#' * 20, 'red'))\n",
    "\n",
    "# Check the shapes of the subsets\n",
    "print(\"Shape of input_parameters_train:\", input_parameters_train.shape)\n",
    "print(\"Shape of input_parameters_test:\", input_parameters_test.shape)\n",
    "print(\"Shape of inputs_train:\", inputs_train.shape)\n",
    "print(\"Shape of inputs_test:\", inputs_test.shape)\n",
    "print(\"Shape of outputs_train:\", outputs_train.shape)\n",
    "print(\"Shape of outputs_test:\", outputs_test.shape)\n",
    "print(colored('#' * 20, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6df93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.404405Z",
     "iopub.status.busy": "2024-12-29T06:12:03.403981Z",
     "iopub.status.idle": "2024-12-29T06:12:03.415190Z",
     "shell.execute_reply": "2024-12-29T06:12:03.414837Z"
    },
    "papermill": {
     "duration": 0.015575,
     "end_time": "2024-12-29T06:12:03.416011",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.400436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stove_source_fields_only = load_and_combine_groups(stove_source_fields_only_groups, 'Source only', combine=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of these full training fields available I am using only n_used fields for estimating the data-driven loss term \n",
    "input_parameters_train_used = input_parameters_train[:n_used, :]\n",
    "print(\"Shape of input_parameters_train_used:\", input_parameters_train_used.shape)\n",
    "inputs_train_used = inputs_train[:n_used, :, :]\n",
    "print(\"Shape of inputs_train_used:\", inputs_train_used.shape)\n",
    "outputs_train_used = outputs_train[:n_used, :, :, :]\n",
    "print(\"Shape of outputs_train_used:\", outputs_train_used.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae139a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.422933Z",
     "iopub.status.busy": "2024-12-29T06:12:03.422647Z",
     "iopub.status.idle": "2024-12-29T06:12:03.760790Z",
     "shell.execute_reply": "2024-12-29T06:12:03.760336Z"
    },
    "papermill": {
     "duration": 0.342666,
     "end_time": "2024-12-29T06:12:03.761733",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.419067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_neurons_branch: Number of input neurons in the branch net.\n",
    "input_neurons_trunk: Number of input neurons in the trunk net.\n",
    "p: Number of output neurons in both the branch and trunk net.\n",
    "\"\"\"\n",
    "\n",
    "p = 128 # Number of output neurons in both the branch and trunk net.\n",
    "\n",
    "input_neurons_branch = (ny, nx) # Specify input size of image as a tuple (height, width)\n",
    "n_channels = 1\n",
    "num_filters = [40, 60, 80, 100]\n",
    "filter_sizes = [3, 3, 3, 3]\n",
    "strides = [1]*len(num_filters)\n",
    "paddings = [0]*len(num_filters)\n",
    "poolings = [('avg', 2, 2), ('avg', 2, 2), ('avg', 2, 2), ('avg', 2, 2)]  # Pooling layer specification (type, kernel_size, stride)\n",
    "end_MLP_layersizes = [150, 150, p]\n",
    "activation = nn.ReLU() # nn.SiLU() #Sin() #nn.LeakyReLU() #nn.Tanh()\n",
    "branch_net = ConvNet(input_neurons_branch, n_channels, num_filters, filter_sizes, strides, paddings, poolings, end_MLP_layersizes, activation)\n",
    "branch_net.to(device)\n",
    "# print(branch_net)\n",
    "print('BRANCH-NET SUMMARY:')\n",
    "summary(branch_net, input_size=(n_channels, ny, nx))  # input shape is (channels, height, width)\n",
    "print('#'*100)\n",
    "\n",
    "input_neurons_trunk = 3 # 3 corresponds to t, x and y\n",
    "trunk_net = DenseNet(layersizes=[input_neurons_trunk] + [128]*4 + [p], activation=nn.SiLU()) #Sin() #nn.LeakyReLU() #nn.Tanh()\n",
    "trunk_net.to(device)\n",
    "# print(trunk_net)\n",
    "print('TRUNK-NET SUMMARY:')\n",
    "summary(trunk_net, input_size=(input_neurons_trunk,))\n",
    "print('#'*100)\n",
    "\n",
    "model = Vanilla_NO_model(branch_net, trunk_net)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e3c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.770268Z",
     "iopub.status.busy": "2024-12-29T06:12:03.769830Z",
     "iopub.status.idle": "2024-12-29T06:12:03.772719Z",
     "shell.execute_reply": "2024-12-29T06:12:03.772280Z"
    },
    "papermill": {
     "duration": 0.007799,
     "end_time": "2024-12-29T06:12:03.773511",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.765712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_learnable_parameters = count_learnable_parameters(branch_net) + count_learnable_parameters(trunk_net)\n",
    "print(\"Total number of learnable parameters:\", num_learnable_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdc4221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.780941Z",
     "iopub.status.busy": "2024-12-29T06:12:03.780577Z",
     "iopub.status.idle": "2024-12-29T06:12:03.783617Z",
     "shell.execute_reply": "2024-12-29T06:12:03.783216Z"
    },
    "papermill": {
     "duration": 0.007568,
     "end_time": "2024-12-29T06:12:03.784363",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.776795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def u_pred(net, inputs, t, x, y):\n",
    "    factor = t*(x-(-L))*(x-L)*(y-(-L))*(y-L)/(T*(2*L)*(2*L)*(2*L)*(2*L)) # (neval, 1) # enforcing ICs and BCs in hard way\n",
    "    factor_repeated = factor.T.repeat(inputs.shape[0], 1)# (bs, neval) # Repeat factor to match the batch size\n",
    "    u = net(inputs, torch.hstack([t, x, y]))*factor_repeated # (bs, neval)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be39e306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.791770Z",
     "iopub.status.busy": "2024-12-29T06:12:03.791402Z",
     "iopub.status.idle": "2024-12-29T06:12:03.796191Z",
     "shell.execute_reply": "2024-12-29T06:12:03.795792Z"
    },
    "papermill": {
     "duration": 0.009344,
     "end_time": "2024-12-29T06:12:03.796977",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.787633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_pde_residual(net, source_fields_parameters, source_fields, t, x, y):\n",
    "    \n",
    "    # Using forward automatic differention to estimate derivatives in the physics informed loss\n",
    "    tangent_t, tangent_x, tangent_y = torch.ones(t.shape).to(device), torch.ones(x.shape).to(device), torch.ones(y.shape).to(device)\n",
    "    ut  = FWDAD_first_order_derivative(lambda t: u_pred(net, source_fields, t, x, y), t, tangent_t)  # (bs, neval_c) \n",
    "    uxx = FWDAD_second_order_derivative(lambda x: u_pred(net, source_fields, t, x, y), x, tangent_x) # (bs, neval_c)\n",
    "    uyy = FWDAD_second_order_derivative(lambda y: u_pred(net, source_fields, t, x, y), y, tangent_y) # (bs, neval_c)\n",
    "    \n",
    "    bs_ = source_fields.shape[0]\n",
    "    sf_values_ = torch.zeros((bs_, x.shape[0], 1)).to(device)\n",
    "    for j in range(bs_):\n",
    "        source_class = Source(a=source_fields_parameters[j][3], r=source_fields_parameters[j][2], \n",
    "                      x=x, y=y, \n",
    "                      xc=0., yc=0.,\n",
    "                      device=device)\n",
    "        shape = get_key_from_value(shape_map, source_fields_parameters[j, 0])\n",
    "        sf_values_[j] = source_class.type_source(shape, num_sides=int(source_fields_parameters[j, 1])) # source function: s(x, y) values\n",
    "    sf_values = sf_values_.reshape(-1, x.shape[0]) # (bs, neval_c)\n",
    "    \n",
    "    pde_residual = (ut - (D_value*uxx) - (D_value*uyy) - sf_values)**2\n",
    "    \n",
    "    return torch.mean(pde_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc2b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.804283Z",
     "iopub.status.busy": "2024-12-29T06:12:03.803909Z",
     "iopub.status.idle": "2024-12-29T06:12:03.806679Z",
     "shell.execute_reply": "2024-12-29T06:12:03.806278Z"
    },
    "papermill": {
     "duration": 0.007235,
     "end_time": "2024-12-29T06:12:03.807482",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.800247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collocation_points(tc_span, xc_span, yc_span, neval_dict):\n",
    "    tc = tc_span.repeat_interleave(neval_dict['loc']).unsqueeze(-1)\n",
    "    xc = xc_span.flatten().repeat(neval_dict['t']).unsqueeze(-1)\n",
    "    yc = yc_span.flatten().repeat(neval_dict['t']).unsqueeze(-1)\n",
    "    return tc, xc, yc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430a632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T06:12:03.815001Z",
     "iopub.status.busy": "2024-12-29T06:12:03.814802Z",
     "iopub.status.idle": "2024-12-29T10:54:51.166862Z",
     "shell.execute_reply": "2024-12-29T10:54:51.166517Z"
    },
    "papermill": {
     "duration": 16967.357036,
     "end_time": "2024-12-29T10:54:51.167792",
     "exception": false,
     "start_time": "2024-12-29T06:12:03.810756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "bs = 128 # Batch size\n",
    "\n",
    "neval_t = 20  # Number of randomly chosen time points at which output field is evaluated.\n",
    "neval_x = 64 \n",
    "neval_y = 64\n",
    "# neval_loc = neval_x*neval_y  # Number of locations at which output field is evaluated at each time point.\n",
    "\n",
    "neval_c = {'t': neval_t, 'loc': neval_x*neval_y}  # Number of collocation points within the domain.\n",
    "        \n",
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20000, gamma=0.1) # gamma=0.8\n",
    "\n",
    "iteration_list, loss_list, learningrates_list = [], [], []\n",
    "datadriven_loss_list, pinn_loss_list = [], []\n",
    "test_iteration_list, test_loss_list = [], []\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    \n",
    "    if n_used == 0:\n",
    "        datadriven_loss = torch.tensor([0.]).to(device)\n",
    "        # print('*********')\n",
    "    else:\n",
    "        indices_datadriven = torch.randperm(n_used).to(device) # Generate random permutation of indices\n",
    "        inputs_train_used_batch = inputs_train_used.reshape(-1, 1, ny, nx)[indices_datadriven[0:bs]]\n",
    "        outputs_train_used_batch = outputs_train_used.reshape(-1, nt*nx*ny)[indices_datadriven[0:bs]]\n",
    "        # print(f\"Shape of inputs_train_used_batch:\", inputs_train_used_batch.shape) # (bs, no. of channels, height, width)\n",
    "        # print(f\"Shape of outputs_train_used_batch:\", outputs_train_used_batch.shape) # (bs, nt*nx*ny)\n",
    "\n",
    "        predicted_values = u_pred(model, inputs_train_used_batch, \n",
    "                              grid[:, 0].reshape(-1,1), \n",
    "                              grid[:, 1].reshape(-1,1), \n",
    "                              grid[:, 2].reshape(-1,1))  # (bs, neval) = (bs, nt*nx*ny)\n",
    "        target_values = outputs_train_used_batch # (bs, nt*nx*ny)\n",
    "        datadriven_loss = nn.MSELoss()(predicted_values, target_values)\n",
    "        # print('*********')\n",
    "    \n",
    "    num_samples = stove_source_fields_only['input_samples'].shape[0]\n",
    "    indices_pinn = torch.randperm(num_samples).to(device) # Generate random permutation of indices\n",
    "    input_parameters_batch = stove_source_fields_only['input_parameters'][indices_pinn[0:bs]]\n",
    "    inputs_batch = stove_source_fields_only['input_samples'].reshape(-1, 1, ny, nx)[indices_pinn[0:bs]]\n",
    "    # print(f\"Shape of inputs_batch:\", inputs_batch.shape) # (bs, no. of channels, height, width)\n",
    "\n",
    "    # points within the domain\n",
    "    tc_span = td.uniform.Uniform(0., T).sample((neval_c['t'], 1)).to(device)\n",
    "    xc_span = td.uniform.Uniform(-L, L).sample((neval_c['loc'], 1)).to(device)\n",
    "    yc_span = td.uniform.Uniform(-L, L).sample((neval_c['loc'], 1)).to(device)\n",
    "\n",
    "    tc, xc, yc = collocation_points(tc_span, xc_span, yc_span, neval_c)\n",
    "    pinn_loss = loss_pde_residual(model, input_parameters_batch, inputs_batch, tc, xc, yc)\n",
    "    # print('*********')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = datadriven_loss + pinn_loss\n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if iteration % 500 == 0:\n",
    "        # Test loss calculation\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            test_predicted_values = u_pred(model, inputs_test.reshape(-1, 1, ny, nx), \n",
    "                          grid[:, 0].reshape(-1,1), \n",
    "                          grid[:, 1].reshape(-1,1), \n",
    "                          grid[:, 2].reshape(-1,1))  # (bs, neval) = (bs, nt*nx*ny)\n",
    "            test_loss = nn.MSELoss()(test_predicted_values, outputs_test.reshape(-1, nt*nx*ny))\n",
    "            test_iteration_list.append(iteration)\n",
    "            test_loss_list.append(test_loss.item())  \n",
    "        model.train()  # Switch back to training mode\n",
    "        print('Iteration %s -' % iteration, 'loss = %f,' % loss,\n",
    "              'data-driven loss = %f,' % datadriven_loss,'pinn loss = %f,' % pinn_loss,\n",
    "              'learning rate = %f,' % optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "              'test loss = %f' % test_loss)\n",
    "\n",
    "    iteration_list.append(iteration)\n",
    "    loss_list.append(loss.item())\n",
    "    datadriven_loss_list.append(datadriven_loss.item())\n",
    "    pinn_loss_list.append(pinn_loss.item())\n",
    "    learningrates_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "    \n",
    "if save == True:\n",
    "    np.save(os.path.join(resultdir,'iteration_list.npy'), np.asarray(iteration_list))\n",
    "    np.save(os.path.join(resultdir,'loss_list.npy'), np.asarray(loss_list))\n",
    "    np.save(os.path.join(resultdir, 'datadriven_loss_list.npy'), np.asarray(datadriven_loss_list))\n",
    "    np.save(os.path.join(resultdir, 'pinn_loss_list.npy'), np.asarray(pinn_loss_list))\n",
    "    np.save(os.path.join(resultdir,'learningrates_list.npy'), np.asarray(learningrates_list))\n",
    "    np.save(os.path.join(resultdir,'test_iteration_list.npy'), np.asarray(test_iteration_list))\n",
    "    np.save(os.path.join(resultdir, 'test_loss_list.npy'), np.asarray(test_loss_list)) \n",
    "\n",
    "plot_loss_terms(resultdir, iteration_list, loss_list, datadriven_loss_list, pinn_loss_list, save)  \n",
    "    \n",
    "plot_training_loss(resultdir, iteration_list, loss_list, save) \n",
    "\n",
    "plot_testing_loss(resultdir, test_iteration_list, test_loss_list, save)\n",
    "\n",
    "plot_training_testing_loss(resultdir, iteration_list, loss_list, test_iteration_list, test_loss_list, save)\n",
    "\n",
    "plot_learningrates(resultdir, iteration_list, learningrates_list, save)  \n",
    "    \n",
    "# end timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "runtime_per_iter = training_time/n_iterations # in sec/iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67807e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T10:54:51.182695Z",
     "iopub.status.busy": "2024-12-29T10:54:51.182280Z",
     "iopub.status.idle": "2024-12-29T10:54:51.189316Z",
     "shell.execute_reply": "2024-12-29T10:54:51.188988Z"
    },
    "papermill": {
     "duration": 0.015244,
     "end_time": "2024-12-29T10:54:51.190101",
     "exception": false,
     "start_time": "2024-12-29T10:54:51.174857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save == True:\n",
    "    torch.save(model.state_dict(), os.path.join(resultdir,'model_state_dict.pt'))\n",
    "# model.load_state_dict(torch.load(os.path.join(resultdir, 'model_state_dict.pt'), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521aff73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T10:54:51.204322Z",
     "iopub.status.busy": "2024-12-29T10:54:51.204179Z",
     "iopub.status.idle": "2024-12-29T11:00:21.869422Z",
     "shell.execute_reply": "2024-12-29T11:00:21.869085Z"
    },
    "papermill": {
     "duration": 330.852047,
     "end_time": "2024-12-29T11:00:22.048896",
     "exception": false,
     "start_time": "2024-12-29T10:54:51.196849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions_test = u_pred(model, inputs_test.reshape(-1, 1, ny, nx), \n",
    "                          grid[:, 0].reshape(-1,1), \n",
    "                          grid[:, 1].reshape(-1,1), \n",
    "                          grid[:, 2].reshape(-1,1))  # (bs, neval) = (bs, nt*nx*ny)\n",
    "# print(predictions_test.shape)\n",
    "\n",
    "mse_list, r2score_list, relerror_list = [], [], []\n",
    "    \n",
    "for i in range(inputs_test.shape[0]):\n",
    "    \n",
    "    prediction_i = predictions_test[i].reshape(1, -1) # (1, nt*nx*ny)\n",
    "    target_i = outputs_test[i].reshape(1, -1) # (1, nt*nx*ny)\n",
    "\n",
    "    mse_i = F.mse_loss(prediction_i.cpu(), target_i.cpu())\n",
    "    r2score_i = metrics.r2_score(target_i.flatten().cpu().detach().numpy(), prediction_i.flatten().cpu().detach().numpy()) \n",
    "    relerror_i = np.linalg.norm(target_i.flatten().cpu().detach().numpy() - prediction_i.flatten().cpu().detach().numpy()) / np.linalg.norm(target_i.flatten().cpu().detach().numpy())\n",
    "        \n",
    "    mse_list.append(mse_i.item())\n",
    "    r2score_list.append(r2score_i.item())\n",
    "    relerror_list.append(relerror_i.item())\n",
    "    \n",
    "    # Plot the full solution-field for few cases (2 groups i.e., 10*2=20):\n",
    "    if (i+1) <= 20:\n",
    "        print(colored('TEST SAMPLE '+str(i+1), 'red'))\n",
    "        shape = get_key_from_value(shape_map, input_parameters_test[i, 0])\n",
    "        print(colored(f\"Shape = {shape}, r = {input_parameters_test[i,2]:.3f}, a_value = {input_parameters_test[i,3]:.3f}\", 'red'))\n",
    "        \n",
    "        r2score_i = float('%.4f'%r2score_i)\n",
    "        relerror_i = float('%.4f'%relerror_i)\n",
    "        print('Rel. L2 Error = '+str(relerror_i)+', R2 score = '+str(r2score_i))\n",
    "        \n",
    "        # Plotting \n",
    "        plot_source(i, x_span, y_span, inputs_test[i], f\"{shape.capitalize()} Source\", 'hot', resultdir, save)\n",
    "        \n",
    "        cmap = 'hot'  # Color map\n",
    "        fontsize = 14  # Font size for labels and titles\n",
    "        levels = 100\n",
    "        plot_solution(i, x_span, y_span, target_i.reshape(nt,ny,nx), t_span, f\"True Solution for {shape.capitalize()} Source\", cmap, fontsize, levels, resultdir, save, 'True-Solution')\n",
    "        plot_solution(i, x_span, y_span, prediction_i.reshape(nt,ny,nx), t_span, f\"Predicted Solution for {shape.capitalize()} Source\", cmap, fontsize, levels, resultdir, save, 'Predicted-Solution')\n",
    "        plot_solution(i, x_span, y_span, torch.abs(target_i.reshape(nt,ny,nx) - prediction_i.reshape(nt,ny,nx)), t_span, f\"Absolute error for {shape.capitalize()} Source\", cmap, fontsize, levels, resultdir, save, 'Absolute error')\n",
    "        print(colored('#'*230, 'green'))\n",
    "\n",
    "mse = sum(mse_list) / len(mse_list)\n",
    "print(\"Mean Squared Error Test:\\n\", mse)\n",
    "r2score = sum(r2score_list) / len(r2score_list)\n",
    "print(\"R2 score Test:\\n\", r2score)\n",
    "relerror = sum(relerror_list) / len(relerror_list)\n",
    "print(\"Rel. L2 Error Test:\\n\", relerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac31ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T11:00:22.804712Z",
     "iopub.status.busy": "2024-12-29T11:00:22.804434Z",
     "iopub.status.idle": "2024-12-29T11:00:22.875170Z",
     "shell.execute_reply": "2024-12-29T11:00:22.874786Z"
    },
    "papermill": {
     "duration": 0.510099,
     "end_time": "2024-12-29T11:00:22.875991",
     "exception": false,
     "start_time": "2024-12-29T11:00:22.365892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    \"input_parameters_test\": input_parameters_test.cpu(),\n",
    "    \"inputs_test\": inputs_test.cpu(),\n",
    "    \"outputs_test\": outputs_test.cpu(),\n",
    "    \"predictions_test\": predictions_test.reshape(-1, nt, ny, nx).cpu()\n",
    "}\n",
    "for key, value in test_dict.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "print(colored('#'*230, 'green'))\n",
    "\n",
    "if save == True:\n",
    "    torch.save(test_dict, os.path.join(resultdir,'test_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965287e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T11:00:23.819800Z",
     "iopub.status.busy": "2024-12-29T11:00:23.819561Z",
     "iopub.status.idle": "2024-12-29T11:00:23.822384Z",
     "shell.execute_reply": "2024-12-29T11:00:23.822043Z"
    },
    "papermill": {
     "duration": 0.507919,
     "end_time": "2024-12-29T11:00:23.823198",
     "exception": false,
     "start_time": "2024-12-29T11:00:23.315279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_metrics(mse, r2score, relerror, training_time, runtime_per_iter, resultdir, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9542a7",
   "metadata": {
    "papermill": {
     "duration": 0.862097,
     "end_time": "2024-12-29T11:00:25.712131",
     "exception": false,
     "start_time": "2024-12-29T11:00:24.850034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcdbede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17312.674165,
   "end_time": "2024-12-29T11:00:28.240723",
   "environment_variables": {},
   "exception": null,
   "input_path": "a_PI-Vanilla-NO.ipynb",
   "output_path": "results/a_PI-Vanilla-NO/seed=0/output_seed=0.ipynb",
   "parameters": {
    "save": true,
    "seed": 0
   },
   "start_time": "2024-12-29T06:11:55.566558",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
