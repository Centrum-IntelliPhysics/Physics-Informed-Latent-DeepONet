{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97031e5",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [21]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f24266",
   "metadata": {
    "papermill": {
     "duration": 0.004244,
     "end_time": "2025-03-28T08:25:39.468715",
     "exception": false,
     "start_time": "2025-03-28T08:25:39.464471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comparisons\n",
    "\n",
    "This code can execute the following variants of losses:  \n",
    "\n",
    "1. **Variant 1:**  Purely Physics  \n",
    "   $L_{\\theta} = L_{\\text{PDE}}$  \n",
    "   Use $n_{\\text{used}} = 0$  \n",
    "\n",
    "2. **Variant 2:**  Physics + Data  \n",
    "   $L_{\\theta} = L_{\\text{PDE}} + \\Sigma_{i=1}^{n_{\\text{used}}}\\| u_i - \\hat{u}_i \\|_2^2$  \n",
    "   Use $n_{\\text{used}} \\in (0, 500]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224272da",
   "metadata": {
    "papermill": {
     "duration": 0.003642,
     "end_time": "2025-03-28T08:25:39.476281",
     "exception": false,
     "start_time": "2025-03-28T08:25:39.472639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "All the results presented were obtained as follows:\n",
    "1. By estimating the gradients in the physics-informed loss terms using forward mode automatic differentiation (AD).\n",
    "2. The output field values at given grid points were computed in one forward pass of the network using the einsum function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1395ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:39.484160Z",
     "iopub.status.busy": "2025-03-28T08:25:39.484006Z",
     "iopub.status.idle": "2025-03-28T08:25:41.977492Z",
     "shell.execute_reply": "2025-03-28T08:25:41.977045Z"
    },
    "papermill": {
     "duration": 2.498527,
     "end_time": "2025-03-28T08:25:41.978467",
     "exception": false,
     "start_time": "2025-03-28T08:25:39.479940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.distributions as td\n",
    "import math\n",
    "from sklearn import metrics\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from utils.networks import *\n",
    "from utils.visualizer_misc import *\n",
    "from utils.forward_autodiff import *\n",
    "from utils.misc import *\n",
    "\n",
    "from utils.deeponet_networks_2d import *\n",
    "from utils.misc_stove import *\n",
    "from utils.visualizer_stove import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e21cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:41.987023Z",
     "iopub.status.busy": "2025-03-28T08:25:41.986784Z",
     "iopub.status.idle": "2025-03-28T08:25:41.989383Z",
     "shell.execute_reply": "2025-03-28T08:25:41.989019Z"
    },
    "papermill": {
     "duration": 0.007421,
     "end_time": "2025-03-28T08:25:41.990015",
     "exception": false,
     "start_time": "2025-03-28T08:25:41.982594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tag this cell with 'parameters'\n",
    "# parameters\n",
    "seed = 0 # Seed number.\n",
    "n_used = 0 # Ensure n_used is a multiple of 10 (as group size is 10) # Number of full training fields used for estimating the data-driven loss term\n",
    "n_iterations = 1000 # Number of iterations.\n",
    "save = False # Save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15f9ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:41.997991Z",
     "iopub.status.busy": "2025-03-28T08:25:41.997833Z",
     "iopub.status.idle": "2025-03-28T08:25:42.000414Z",
     "shell.execute_reply": "2025-03-28T08:25:42.000072Z"
    },
    "papermill": {
     "duration": 0.007307,
     "end_time": "2025-03-28T08:25:42.001043",
     "exception": false,
     "start_time": "2025-03-28T08:25:41.993736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save == True:\n",
    "    resultdir = os.path.join(os.getcwd(),'results','ForwardAD_neval_c','a_Vanilla-NO_ForwardADeinsum') \n",
    "    if not os.path.exists(resultdir):\n",
    "        os.makedirs(resultdir)\n",
    "else:\n",
    "    resultdir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65cb4cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:42.008877Z",
     "iopub.status.busy": "2025-03-28T08:25:42.008722Z",
     "iopub.status.idle": "2025-03-28T08:25:42.011921Z",
     "shell.execute_reply": "2025-03-28T08:25:42.011564Z"
    },
    "papermill": {
     "duration": 0.007818,
     "end_time": "2025-03-28T08:25:42.012515",
     "exception": false,
     "start_time": "2025-03-28T08:25:42.004697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 0\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d11f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:42.020565Z",
     "iopub.status.busy": "2025-03-28T08:25:42.020400Z",
     "iopub.status.idle": "2025-03-28T08:25:42.387658Z",
     "shell.execute_reply": "2025-03-28T08:25:42.387256Z"
    },
    "papermill": {
     "duration": 0.372025,
     "end_time": "2025-03-28T08:25:42.388307",
     "exception": false,
     "start_time": "2025-03-28T08:25:42.016282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a5e0b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:42.396857Z",
     "iopub.status.busy": "2025-03-28T08:25:42.396685Z",
     "iopub.status.idle": "2025-03-28T08:25:42.601148Z",
     "shell.execute_reply": "2025-03-28T08:25:42.600746Z"
    },
    "papermill": {
     "duration": 0.209431,
     "end_time": "2025-03-28T08:25:42.601808",
     "exception": false,
     "start_time": "2025-03-28T08:25:42.392377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of t_span: torch.Size([20])\n",
      "Shape of x_span: torch.Size([64, 64])\n",
      "Shape of y_span: torch.Size([64, 64])\n",
      "shapes is a dictionary with 10 keys.\n"
     ]
    }
   ],
   "source": [
    "metadata_np = np.load(os.path.join('..','..','data/2D_Stove/metadata.npz'), allow_pickle=True)\n",
    "metadata = convert_metadata_to_torch(metadata_np, device)\n",
    "for key, value in metadata.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"Shape of {key}: {value.shape}\")\n",
    "        elif isinstance(value, dict):\n",
    "            print(f\"{key} is a dictionary with {len(value)} keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f912b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:42.610402Z",
     "iopub.status.busy": "2025-03-28T08:25:42.610234Z",
     "iopub.status.idle": "2025-03-28T08:25:42.692956Z",
     "shell.execute_reply": "2025-03-28T08:25:42.692549Z"
    },
    "papermill": {
     "duration": 0.087656,
     "end_time": "2025-03-28T08:25:42.693601",
     "exception": false,
     "start_time": "2025-03-28T08:25:42.605945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt = 20 , nx = 64 ny = 64\n",
      "Shape of t-span, x-span, and y-span: torch.Size([20]) torch.Size([64, 64]) torch.Size([64, 64])\n",
      "t-span: tensor([0.0500, 0.1000, 0.1500, 0.2000, 0.2500, 0.3000, 0.3500, 0.4000, 0.4500,\n",
      "        0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,\n",
      "        0.9500, 1.0000], device='cuda:0')\n",
      "x-span: tensor([[-1.9688, -1.9062, -1.8438,  ...,  1.8438,  1.9062,  1.9688],\n",
      "        [-1.9688, -1.9062, -1.8438,  ...,  1.8438,  1.9062,  1.9688],\n",
      "        [-1.9688, -1.9062, -1.8438,  ...,  1.8438,  1.9062,  1.9688],\n",
      "        ...,\n",
      "        [-1.9688, -1.9062, -1.8438,  ...,  1.8438,  1.9062,  1.9688],\n",
      "        [-1.9688, -1.9062, -1.8438,  ...,  1.8438,  1.9062,  1.9688],\n",
      "        [-1.9688, -1.9062, -1.8438,  ...,  1.8438,  1.9062,  1.9688]],\n",
      "       device='cuda:0')\n",
      "y-span: tensor([[-1.9688, -1.9688, -1.9688,  ..., -1.9688, -1.9688, -1.9688],\n",
      "        [-1.9062, -1.9062, -1.9062,  ..., -1.9062, -1.9062, -1.9062],\n",
      "        [-1.8438, -1.8438, -1.8438,  ..., -1.8438, -1.8438, -1.8438],\n",
      "        ...,\n",
      "        [ 1.8438,  1.8438,  1.8438,  ...,  1.8438,  1.8438,  1.8438],\n",
      "        [ 1.9062,  1.9062,  1.9062,  ...,  1.9062,  1.9062,  1.9062],\n",
      "        [ 1.9688,  1.9688,  1.9688,  ...,  1.9688,  1.9688,  1.9688]],\n",
      "       device='cuda:0')\n",
      "Shape of grid: torch.Size([81920, 3])\n",
      "grid: tensor([[ 0.0500, -1.9688, -1.9688],\n",
      "        [ 0.0500, -1.9062, -1.9688],\n",
      "        [ 0.0500, -1.8438, -1.9688],\n",
      "        ...,\n",
      "        [ 1.0000,  1.8438,  1.9688],\n",
      "        [ 1.0000,  1.9062,  1.9688],\n",
      "        [ 1.0000,  1.9688,  1.9688]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t_span, x_span, y_span = metadata['t_span'], metadata['x_span'], metadata['y_span']\n",
    "\n",
    "nt, nx, ny = len(t_span), len(x_span), len(y_span) # number of discretizations in time, location_x and location_y.\n",
    "print(\"nt =\",nt, \", nx =\",nx, \"ny =\",ny)\n",
    "print(\"Shape of t-span, x-span, and y-span:\",t_span.shape, x_span.shape, y_span.shape)\n",
    "print(\"t-span:\", t_span)\n",
    "print(\"x-span:\", x_span)\n",
    "print(\"y-span:\", y_span)\n",
    "\n",
    "L = 2.         # Simulation domain [-L, L]^2\n",
    "T = 1.         # Simulation time\n",
    "D_value = 1.0  # Diffusion coefficient  \n",
    "\n",
    "grid = torch.vstack((t_span.repeat_interleave(ny*nx), \n",
    "              x_span.flatten().repeat(nt),\n",
    "              y_span.flatten().repeat(nt))).T\n",
    "print(\"Shape of grid:\", grid.shape) # (nt*nx*ny, 3)\n",
    "print(\"grid:\", grid) # time, location_x, location_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f4ead1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:42.702126Z",
     "iopub.status.busy": "2025-03-28T08:25:42.701956Z",
     "iopub.status.idle": "2025-03-28T08:25:42.708865Z",
     "shell.execute_reply": "2025-03-28T08:25:42.708488Z"
    },
    "papermill": {
     "duration": 0.011821,
     "end_time": "2025-03-28T08:25:42.709489",
     "exception": false,
     "start_time": "2025-03-28T08:25:42.697668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(NpzFile '../../data/2D_Stove/stove_full_solution_fields.npz' with keys: full_solution_all_groups)\n",
      "KeysView(NpzFile '../../data/2D_Stove/stove_source_fields_only.npz' with keys: only_sources_all_groups)\n"
     ]
    }
   ],
   "source": [
    "stove_full_solution_fields_groups_np = np.load(os.path.join('..','..','data/2D_Stove/stove_full_solution_fields.npz'), allow_pickle=True)\n",
    "print(stove_full_solution_fields_groups_np.keys())\n",
    "\n",
    "stove_source_fields_only_groups_np = np.load(os.path.join('..','..','data/2D_Stove/stove_source_fields_only.npz'), allow_pickle=True)\n",
    "print(stove_source_fields_only_groups_np.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "998de134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:42.717972Z",
     "iopub.status.busy": "2025-03-28T08:25:42.717812Z",
     "iopub.status.idle": "2025-03-28T08:25:45.357798Z",
     "shell.execute_reply": "2025-03-28T08:25:45.355682Z"
    },
    "papermill": {
     "duration": 2.645255,
     "end_time": "2025-03-28T08:25:45.358807",
     "exception": false,
     "start_time": "2025-03-28T08:25:42.713552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stove_full_solution_fields_groups:\n",
      "Group 0:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "  Output Samples shape: torch.Size([10, 20, 64, 64])\n",
      "Group 1:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "  Output Samples shape: torch.Size([10, 20, 64, 64])\n",
      "\u001b[32m######################################################################################################################################################################################################################################\u001b[0m\n",
      "stove_source_fields_only_groups:\n",
      "Group 0:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "Group 1:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "\u001b[32m######################################################################################################################################################################################################################################\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Convert the NumPy groups to Pytorch\n",
    "stove_full_solution_fields_groups = convert_groupdict_to_torch(stove_full_solution_fields_groups_np, device)\n",
    "stove_source_fields_only_groups = convert_groupdict_to_torch(stove_source_fields_only_groups_np, device)\n",
    "\n",
    "# Check the shapes\n",
    "print('stove_full_solution_fields_groups:')\n",
    "check_shapes(stove_full_solution_fields_groups)\n",
    "print(colored('#' * 230, 'green'))\n",
    "\n",
    "print('stove_source_fields_only_groups:')\n",
    "check_shapes(stove_source_fields_only_groups)\n",
    "print(colored('#' * 230, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a174b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.370737Z",
     "iopub.status.busy": "2025-03-28T08:25:45.369990Z",
     "iopub.status.idle": "2025-03-28T08:25:45.381692Z",
     "shell.execute_reply": "2025-03-28T08:25:45.381227Z"
    },
    "papermill": {
     "duration": 0.018612,
     "end_time": "2025-03-28T08:25:45.382339",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.363727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Group:\n",
      "\u001b[31m####################\u001b[0m\n",
      "Group Data Shapes:\n",
      "Group 4:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "  Output Samples shape: torch.Size([10, 20, 64, 64])\n",
      "--------------------------------------------------\n",
      "Group 10:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "  Output Samples shape: torch.Size([10, 20, 64, 64])\n",
      "--------------------------------------------------\n",
      "\u001b[32m######################################################################################################################################################################################################################################\u001b[0m\n",
      "Testing Group:\n",
      "\u001b[31m####################\u001b[0m\n",
      "Group Data Shapes:\n",
      "Group 26:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "  Output Samples shape: torch.Size([10, 20, 64, 64])\n",
      "--------------------------------------------------\n",
      "Group 35:\n",
      "  Input Parameters shape: torch.Size([10, 4])\n",
      "  Input Samples shape: torch.Size([10, 64, 64])\n",
      "  Output Samples shape: torch.Size([10, 20, 64, 64])\n",
      "--------------------------------------------------\n",
      "\u001b[32m######################################################################################################################################################################################################################################\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing groups\n",
    "train_group, test_group = split_groups(stove_full_solution_fields_groups, seed, train_size=50, test_size=10)\n",
    "\n",
    "# Print the shapes for verification\n",
    "print(\"Training Group:\")\n",
    "print(colored('#' * 20, 'red'))\n",
    "print_group_shapes(train_group)\n",
    "print(colored('#' * 230, 'green'))\n",
    "print(\"Testing Group:\")\n",
    "print(colored('#' * 20, 'red'))\n",
    "print_group_shapes(test_group)\n",
    "print(colored('#' * 230, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca1da6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.391193Z",
     "iopub.status.busy": "2025-03-28T08:25:45.390828Z",
     "iopub.status.idle": "2025-03-28T08:25:45.400823Z",
     "shell.execute_reply": "2025-03-28T08:25:45.400397Z"
    },
    "papermill": {
     "duration": 0.015043,
     "end_time": "2025-03-28T08:25:45.401451",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.386408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shapes:\n",
      "  Input Parameters Shape: torch.Size([500, 4])\n",
      "  Input Samples Shape: torch.Size([500, 64, 64])\n",
      "  Output Samples Shape: torch.Size([500, 20, 64, 64])\n",
      "Test Data Shapes:\n",
      "  Input Parameters Shape: torch.Size([100, 4])\n",
      "  Input Samples Shape: torch.Size([100, 64, 64])\n",
      "  Output Samples Shape: torch.Size([100, 20, 64, 64])\n",
      "\u001b[31m####################\u001b[0m\n",
      "Shape of input_parameters_train: torch.Size([500, 4])\n",
      "Shape of input_parameters_test: torch.Size([100, 4])\n",
      "Shape of inputs_train: torch.Size([500, 64, 64])\n",
      "Shape of inputs_test: torch.Size([100, 64, 64])\n",
      "Shape of outputs_train: torch.Size([500, 20, 64, 64])\n",
      "Shape of outputs_test: torch.Size([100, 20, 64, 64])\n",
      "\u001b[32m####################\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_data = load_and_combine_groups(train_group, 'Train', combine=True, device=device)\n",
    "input_parameters_train = train_data['input_parameters']\n",
    "inputs_train = train_data['input_samples']\n",
    "outputs_train = train_data['output_samples']\n",
    "\n",
    "test_data = load_and_combine_groups(test_group, 'Test', combine=True, device=device)\n",
    "input_parameters_test = test_data['input_parameters']\n",
    "inputs_test = test_data['input_samples']\n",
    "outputs_test = test_data['output_samples']\n",
    "\n",
    "print(colored('#' * 20, 'red'))\n",
    "\n",
    "# Check the shapes of the subsets\n",
    "print(\"Shape of input_parameters_train:\", input_parameters_train.shape)\n",
    "print(\"Shape of input_parameters_test:\", input_parameters_test.shape)\n",
    "print(\"Shape of inputs_train:\", inputs_train.shape)\n",
    "print(\"Shape of inputs_test:\", inputs_test.shape)\n",
    "print(\"Shape of outputs_train:\", outputs_train.shape)\n",
    "print(\"Shape of outputs_test:\", outputs_test.shape)\n",
    "print(colored('#' * 20, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f6df93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.410235Z",
     "iopub.status.busy": "2025-03-28T08:25:45.410068Z",
     "iopub.status.idle": "2025-03-28T08:25:45.420338Z",
     "shell.execute_reply": "2025-03-28T08:25:45.419956Z"
    },
    "papermill": {
     "duration": 0.015319,
     "end_time": "2025-03-28T08:25:45.420959",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.405640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source only Data Shapes:\n",
      "  Input Parameters Shape: torch.Size([2000, 4])\n",
      "  Input Samples Shape: torch.Size([2000, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "stove_source_fields_only = load_and_combine_groups(stove_source_fields_only_groups, 'Source only', combine=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e0c383e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.429736Z",
     "iopub.status.busy": "2025-03-28T08:25:45.429571Z",
     "iopub.status.idle": "2025-03-28T08:25:45.432812Z",
     "shell.execute_reply": "2025-03-28T08:25:45.432466Z"
    },
    "papermill": {
     "duration": 0.008444,
     "end_time": "2025-03-28T08:25:45.433553",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.425109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input_parameters_train_used: torch.Size([0, 4])\n",
      "Shape of inputs_train_used: torch.Size([0, 64, 64])\n",
      "Shape of outputs_train_used: torch.Size([0, 20, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Of these full training fields available I am using only n_used fields for estimating the data-driven loss term \n",
    "input_parameters_train_used = input_parameters_train[:n_used, :]\n",
    "print(\"Shape of input_parameters_train_used:\", input_parameters_train_used.shape)\n",
    "inputs_train_used = inputs_train[:n_used, :, :]\n",
    "print(\"Shape of inputs_train_used:\", inputs_train_used.shape)\n",
    "outputs_train_used = outputs_train[:n_used, :, :, :]\n",
    "print(\"Shape of outputs_train_used:\", outputs_train_used.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ae139a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.442621Z",
     "iopub.status.busy": "2025-03-28T08:25:45.442346Z",
     "iopub.status.idle": "2025-03-28T08:25:45.659618Z",
     "shell.execute_reply": "2025-03-28T08:25:45.659222Z"
    },
    "papermill": {
     "duration": 0.222398,
     "end_time": "2025-03-28T08:25:45.660227",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.437829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRANCH-NET SUMMARY:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 40, 62, 62]             400\n",
      "              ReLU-2           [-1, 40, 62, 62]               0\n",
      "         AvgPool2d-3           [-1, 40, 31, 31]               0\n",
      "            Conv2d-4           [-1, 60, 29, 29]          21,660\n",
      "              ReLU-5           [-1, 60, 29, 29]               0\n",
      "         AvgPool2d-6           [-1, 60, 14, 14]               0\n",
      "            Conv2d-7           [-1, 80, 12, 12]          43,280\n",
      "              ReLU-8           [-1, 80, 12, 12]               0\n",
      "         AvgPool2d-9             [-1, 80, 6, 6]               0\n",
      "           Conv2d-10            [-1, 100, 4, 4]          72,100\n",
      "             ReLU-11            [-1, 100, 4, 4]               0\n",
      "        AvgPool2d-12            [-1, 100, 2, 2]               0\n",
      "          Flatten-13                  [-1, 400]               0\n",
      "           Linear-14                  [-1, 150]          60,150\n",
      "             ReLU-15                  [-1, 150]               0\n",
      "           Linear-16                  [-1, 150]          22,650\n",
      "             ReLU-17                  [-1, 150]               0\n",
      "           Linear-18                  [-1, 128]          19,328\n",
      "================================================================\n",
      "Total params: 239,568\n",
      "Trainable params: 239,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 3.73\n",
      "Params size (MB): 0.91\n",
      "Estimated Total Size (MB): 4.66\n",
      "----------------------------------------------------------------\n",
      "####################################################################################################\n",
      "TRUNK-NET SUMMARY:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]             512\n",
      "              SiLU-2                  [-1, 128]               0\n",
      "            Linear-3                  [-1, 128]          16,512\n",
      "              SiLU-4                  [-1, 128]               0\n",
      "            Linear-5                  [-1, 128]          16,512\n",
      "              SiLU-6                  [-1, 128]               0\n",
      "            Linear-7                  [-1, 128]          16,512\n",
      "              SiLU-8                  [-1, 128]               0\n",
      "            Linear-9                  [-1, 128]          16,512\n",
      "================================================================\n",
      "Total params: 66,560\n",
      "Trainable params: 66,560\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 0.26\n",
      "----------------------------------------------------------------\n",
      "####################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Vanilla_NO_model(\n",
       "  (branch_net): ConvNet(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (3): Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): ReLU()\n",
       "      (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (6): Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (7): ReLU()\n",
       "      (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (9): Conv2d(80, 100, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (10): ReLU()\n",
       "      (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (12): Flatten(start_dim=1, end_dim=-1)\n",
       "      (13): Linear(in_features=400, out_features=150, bias=True)\n",
       "      (14): ReLU()\n",
       "      (15): Linear(in_features=150, out_features=150, bias=True)\n",
       "      (16): ReLU()\n",
       "      (17): Linear(in_features=150, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (trunk_net): DenseNet(\n",
       "    (activation): SiLU()\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "      (1-4): 4 x Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input_neurons_branch: Number of input neurons in the branch net.\n",
    "input_neurons_trunk: Number of input neurons in the trunk net.\n",
    "p: Number of output neurons in both the branch and trunk net.\n",
    "\"\"\"\n",
    "\n",
    "p = 128 # Number of output neurons in both the branch and trunk net.\n",
    "\n",
    "input_neurons_branch = (ny, nx) # Specify input size of image as a tuple (height, width)\n",
    "n_channels = 1\n",
    "num_filters = [40, 60, 80, 100]\n",
    "filter_sizes = [3, 3, 3, 3]\n",
    "strides = [1]*len(num_filters)\n",
    "paddings = [0]*len(num_filters)\n",
    "poolings = [('avg', 2, 2), ('avg', 2, 2), ('avg', 2, 2), ('avg', 2, 2)]  # Pooling layer specification (type, kernel_size, stride)\n",
    "end_MLP_layersizes = [150, 150, p]\n",
    "activation = nn.ReLU() # nn.SiLU() #Sin() #nn.LeakyReLU() #nn.Tanh()\n",
    "branch_net = ConvNet(input_neurons_branch, n_channels, num_filters, filter_sizes, strides, paddings, poolings, end_MLP_layersizes, activation)\n",
    "branch_net.to(device)\n",
    "# print(branch_net)\n",
    "print('BRANCH-NET SUMMARY:')\n",
    "summary(branch_net, input_size=(n_channels, ny, nx))  # input shape is (channels, height, width)\n",
    "print('#'*100)\n",
    "\n",
    "input_neurons_trunk = 3 # 3 corresponds to t, x and y\n",
    "trunk_net = DenseNet(layersizes=[input_neurons_trunk] + [128]*4 + [p], activation=nn.SiLU()) #Sin() #nn.LeakyReLU() #nn.Tanh()\n",
    "trunk_net.to(device)\n",
    "# print(trunk_net)\n",
    "print('TRUNK-NET SUMMARY:')\n",
    "summary(trunk_net, input_size=(input_neurons_trunk,))\n",
    "print('#'*100)\n",
    "\n",
    "model = Vanilla_NO_model(branch_net, trunk_net)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "548e3c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.669879Z",
     "iopub.status.busy": "2025-03-28T08:25:45.669718Z",
     "iopub.status.idle": "2025-03-28T08:25:45.672397Z",
     "shell.execute_reply": "2025-03-28T08:25:45.672029Z"
    },
    "papermill": {
     "duration": 0.008178,
     "end_time": "2025-03-28T08:25:45.673010",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.664832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of learnable parameters: 306128\n"
     ]
    }
   ],
   "source": [
    "num_learnable_parameters = count_learnable_parameters(branch_net) + count_learnable_parameters(trunk_net)\n",
    "print(\"Total number of learnable parameters:\", num_learnable_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bdc4221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.682389Z",
     "iopub.status.busy": "2025-03-28T08:25:45.682238Z",
     "iopub.status.idle": "2025-03-28T08:25:45.685299Z",
     "shell.execute_reply": "2025-03-28T08:25:45.684942Z"
    },
    "papermill": {
     "duration": 0.008431,
     "end_time": "2025-03-28T08:25:45.685900",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.677469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def u_pred(net, inputs, t, x, y):\n",
    "    factor = t*(x-(-L))*(x-L)*(y-(-L))*(y-L)/(T*(2*L)*(2*L)*(2*L)*(2*L)) # (neval, 1) # enforcing ICs and BCs in hard way\n",
    "    factor_repeated = factor.T.repeat(inputs.shape[0], 1)# (bs, neval) # Repeat factor to match the batch size\n",
    "    u = net(inputs, torch.hstack([t, x, y]))*factor_repeated # (bs, neval)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be39e306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.695384Z",
     "iopub.status.busy": "2025-03-28T08:25:45.695235Z",
     "iopub.status.idle": "2025-03-28T08:25:45.700359Z",
     "shell.execute_reply": "2025-03-28T08:25:45.699995Z"
    },
    "papermill": {
     "duration": 0.010524,
     "end_time": "2025-03-28T08:25:45.700970",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.690446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_pde_residual(net, source_fields_parameters, source_fields, t, x, y):\n",
    "    \n",
    "    # Using forward automatic differention to estimate derivatives in the physics informed loss\n",
    "    tangent_t, tangent_x, tangent_y = torch.ones(t.shape).to(device), torch.ones(x.shape).to(device), torch.ones(y.shape).to(device)\n",
    "    ut  = FWDAD_first_order_derivative(lambda t: u_pred(net, source_fields, t, x, y), t, tangent_t)  # (bs, neval_c) \n",
    "    uxx = FWDAD_second_order_derivative(lambda x: u_pred(net, source_fields, t, x, y), x, tangent_x) # (bs, neval_c)\n",
    "    uyy = FWDAD_second_order_derivative(lambda y: u_pred(net, source_fields, t, x, y), y, tangent_y) # (bs, neval_c)\n",
    "    \n",
    "    bs_ = source_fields.shape[0]\n",
    "    sf_values_ = torch.zeros((bs_, x.shape[0], 1)).to(device)\n",
    "    for j in range(bs_):\n",
    "        source_class = Source(a=source_fields_parameters[j][3], r=source_fields_parameters[j][2], \n",
    "                      x=x, y=y, \n",
    "                      xc=0., yc=0.,\n",
    "                      device=device)\n",
    "        shape = get_key_from_value(shape_map, source_fields_parameters[j, 0])\n",
    "        sf_values_[j] = source_class.type_source(shape, num_sides=int(source_fields_parameters[j, 1])) # source function: s(x, y) values\n",
    "    sf_values = sf_values_.reshape(-1, x.shape[0]) # (bs, neval_c)\n",
    "    \n",
    "    pde_residual = (ut - (D_value*uxx) - (D_value*uyy) - sf_values)**2\n",
    "    \n",
    "    return torch.mean(pde_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9fc2b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.710396Z",
     "iopub.status.busy": "2025-03-28T08:25:45.710246Z",
     "iopub.status.idle": "2025-03-28T08:25:45.712968Z",
     "shell.execute_reply": "2025-03-28T08:25:45.712615Z"
    },
    "papermill": {
     "duration": 0.0081,
     "end_time": "2025-03-28T08:25:45.713551",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.705451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collocation_points(tc_span, xc_span, yc_span, neval_dict):\n",
    "    tc = tc_span.repeat_interleave(neval_dict['loc']).unsqueeze(-1)\n",
    "    xc = xc_span.flatten().repeat(neval_dict['t']).unsqueeze(-1)\n",
    "    yc = yc_span.flatten().repeat(neval_dict['t']).unsqueeze(-1)\n",
    "    return tc, xc, yc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25cd62e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.723151Z",
     "iopub.status.busy": "2025-03-28T08:25:45.722882Z",
     "iopub.status.idle": "2025-03-28T08:25:45.725001Z",
     "shell.execute_reply": "2025-03-28T08:25:45.724657Z"
    },
    "papermill": {
     "duration": 0.00749,
     "end_time": "2025-03-28T08:25:45.725592",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.718102",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "neval_t = 20  # Number of randomly chosen time points at which output field is evaluated.\n",
    "neval_x = 64 \n",
    "# neval_loc = neval_x*neval_y  # Number of locations at which output field is evaluated at each time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1178dfdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.734989Z",
     "iopub.status.busy": "2025-03-28T08:25:45.734845Z",
     "iopub.status.idle": "2025-03-28T08:25:45.736857Z",
     "shell.execute_reply": "2025-03-28T08:25:45.736498Z"
    },
    "papermill": {
     "duration": 0.007364,
     "end_time": "2025-03-28T08:25:45.737438",
     "exception": false,
     "start_time": "2025-03-28T08:25:45.730074",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "neval_t = 128\n",
    "neval_x = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570e1be",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a430a632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T08:25:45.747156Z",
     "iopub.status.busy": "2025-03-28T08:25:45.747008Z",
     "iopub.status.idle": "2025-03-28T08:25:49.686477Z",
     "shell.execute_reply": "2025-03-28T08:25:49.685733Z"
    },
    "papermill": {
     "duration": 3.945116,
     "end_time": "2025-03-28T08:25:49.687140",
     "exception": true,
     "start_time": "2025-03-28T08:25:45.742024",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 820.75 MiB is free. Including non-PyTorch memory, this process has 78.33 GiB memory in use. Of the allocated memory 76.92 GiB is allocated by PyTorch, and 934.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m yc_span \u001b[38;5;241m=\u001b[39m td\u001b[38;5;241m.\u001b[39muniform\u001b[38;5;241m.\u001b[39mUniform(\u001b[38;5;241m-\u001b[39mL, L)\u001b[38;5;241m.\u001b[39msample((neval_c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m tc, xc, yc \u001b[38;5;241m=\u001b[39m collocation_points(tc_span, xc_span, yc_span, neval_c)\n\u001b[0;32m---> 49\u001b[0m pinn_loss \u001b[38;5;241m=\u001b[39m loss_pde_residual(model, input_parameters_batch, inputs_batch, tc, xc, yc)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# print('*********')\u001b[39;00m\n\u001b[1;32m     52\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mloss_pde_residual\u001b[0;34m(net, source_fields_parameters, source_fields, t, x, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m tangent_t, tangent_x, tangent_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(t\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mones(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mones(y\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m ut  \u001b[38;5;241m=\u001b[39m FWDAD_first_order_derivative(\u001b[38;5;28;01mlambda\u001b[39;00m t: u_pred(net, source_fields, t, x, y), t, tangent_t)  \u001b[38;5;66;03m# (bs, neval_c) \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m uxx \u001b[38;5;241m=\u001b[39m FWDAD_second_order_derivative(\u001b[38;5;28;01mlambda\u001b[39;00m x: u_pred(net, source_fields, t, x, y), x, tangent_x) \u001b[38;5;66;03m# (bs, neval_c)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m uyy \u001b[38;5;241m=\u001b[39m FWDAD_second_order_derivative(\u001b[38;5;28;01mlambda\u001b[39;00m y: u_pred(net, source_fields, t, x, y), y, tangent_y) \u001b[38;5;66;03m# (bs, neval_c)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m bs_ \u001b[38;5;241m=\u001b[39m source_fields\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/scratch4/sgoswam4/sharmila/02_Latent_DeepONet/paper_runs/Comparison_studies-2D_Stove_64x64_NEVALC/../../utils/forward_autodiff.py:14\u001b[0m, in \u001b[0;36mFWDAD_second_order_derivative\u001b[0;34m(f, primals, tangents)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFWDAD_second_order_derivative\u001b[39m(f, primals, tangents):\n\u001b[1;32m     13\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m primals: functorch\u001b[38;5;241m.\u001b[39mjvp(f, (primals,), (tangents,))[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m     _, tangents_out \u001b[38;5;241m=\u001b[39m functorch\u001b[38;5;241m.\u001b[39mjvp(g, (primals,), (tangents,))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tangents_out\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/deprecated.py:78\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, primals, tangents, strict, has_aux)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjvp\u001b[39m(func: Callable, primals: Any, tangents: Any, \u001b[38;5;241m*\u001b[39m, strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m     warn_deprecated(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _impl\u001b[38;5;241m.\u001b[39mjvp(func, primals, tangents, strict\u001b[38;5;241m=\u001b[39mstrict, has_aux\u001b[38;5;241m=\u001b[39mhas_aux)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:927\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, primals, tangents, strict, has_aux)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;129m@exposed_in\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.func\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjvp\u001b[39m(func: Callable, primals: Any, tangents: Any, \u001b[38;5;241m*\u001b[39m, strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    Standing for the Jacobian-vector product, returns a tuple containing\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    the output of `func(*primals)` and the \"Jacobian of ``func`` evaluated at\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _jvp_with_argnums(func, primals, tangents, argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, strict\u001b[38;5;241m=\u001b[39mstrict, has_aux\u001b[38;5;241m=\u001b[39mhas_aux)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/vmap.py:44\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:976\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m    974\u001b[0m     primals \u001b[38;5;241m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m    975\u001b[0m     duals \u001b[38;5;241m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m--> 976\u001b[0m result_duals \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39mduals)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m/scratch4/sgoswam4/sharmila/02_Latent_DeepONet/paper_runs/Comparison_studies-2D_Stove_64x64_NEVALC/../../utils/forward_autodiff.py:13\u001b[0m, in \u001b[0;36mFWDAD_second_order_derivative.<locals>.<lambda>\u001b[0;34m(primals)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFWDAD_second_order_derivative\u001b[39m(f, primals, tangents):\n\u001b[0;32m---> 13\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m primals: functorch\u001b[38;5;241m.\u001b[39mjvp(f, (primals,), (tangents,))[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m     _, tangents_out \u001b[38;5;241m=\u001b[39m functorch\u001b[38;5;241m.\u001b[39mjvp(g, (primals,), (tangents,))\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tangents_out\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/deprecated.py:78\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, primals, tangents, strict, has_aux)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjvp\u001b[39m(func: Callable, primals: Any, tangents: Any, \u001b[38;5;241m*\u001b[39m, strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m     warn_deprecated(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _impl\u001b[38;5;241m.\u001b[39mjvp(func, primals, tangents, strict\u001b[38;5;241m=\u001b[39mstrict, has_aux\u001b[38;5;241m=\u001b[39mhas_aux)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:927\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, primals, tangents, strict, has_aux)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;129m@exposed_in\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.func\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjvp\u001b[39m(func: Callable, primals: Any, tangents: Any, \u001b[38;5;241m*\u001b[39m, strict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    Standing for the Jacobian-vector product, returns a tuple containing\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    the output of `func(*primals)` and the \"Jacobian of ``func`` evaluated at\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _jvp_with_argnums(func, primals, tangents, argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, strict\u001b[38;5;241m=\u001b[39mstrict, has_aux\u001b[38;5;241m=\u001b[39mhas_aux)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/vmap.py:44\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:976\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m    974\u001b[0m     primals \u001b[38;5;241m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m    975\u001b[0m     duals \u001b[38;5;241m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m--> 976\u001b[0m result_duals \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39mduals)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mloss_pde_residual.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m tangent_t, tangent_x, tangent_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(t\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mones(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mones(y\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m ut  \u001b[38;5;241m=\u001b[39m FWDAD_first_order_derivative(\u001b[38;5;28;01mlambda\u001b[39;00m t: u_pred(net, source_fields, t, x, y), t, tangent_t)  \u001b[38;5;66;03m# (bs, neval_c) \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m uxx \u001b[38;5;241m=\u001b[39m FWDAD_second_order_derivative(\u001b[38;5;28;01mlambda\u001b[39;00m x: u_pred(net, source_fields, t, x, y), x, tangent_x) \u001b[38;5;66;03m# (bs, neval_c)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m uyy \u001b[38;5;241m=\u001b[39m FWDAD_second_order_derivative(\u001b[38;5;28;01mlambda\u001b[39;00m y: u_pred(net, source_fields, t, x, y), y, tangent_y) \u001b[38;5;66;03m# (bs, neval_c)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m bs_ \u001b[38;5;241m=\u001b[39m source_fields\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mu_pred\u001b[0;34m(net, inputs, t, x, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m factor \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m*\u001b[39m(x\u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m-\u001b[39mL))\u001b[38;5;241m*\u001b[39m(x\u001b[38;5;241m-\u001b[39mL)\u001b[38;5;241m*\u001b[39m(y\u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m-\u001b[39mL))\u001b[38;5;241m*\u001b[39m(y\u001b[38;5;241m-\u001b[39mL)\u001b[38;5;241m/\u001b[39m(T\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mL)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mL)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mL)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mL)) \u001b[38;5;66;03m# (neval, 1) # enforcing ICs and BCs in hard way\u001b[39;00m\n\u001b[1;32m      3\u001b[0m factor_repeated \u001b[38;5;241m=\u001b[39m factor\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mrepeat(inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;66;03m# (bs, neval) # Repeat factor to match the batch size\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m u \u001b[38;5;241m=\u001b[39m net(inputs, torch\u001b[38;5;241m.\u001b[39mhstack([t, x, y]))\u001b[38;5;241m*\u001b[39mfactor_repeated \u001b[38;5;66;03m# (bs, neval)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m u\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch4/sgoswam4/sharmila/02_Latent_DeepONet/paper_runs/Comparison_studies-2D_Stove_64x64_NEVALC/../../utils/deeponet_networks_2d.py:47\u001b[0m, in \u001b[0;36mVanilla_NO_model.forward\u001b[0;34m(self, branch_inputs, trunk_inputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mbs    :  Batch size.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mc     :  Number of channels in input field image.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03moutputs shape: (bs, neval).\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m branch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranch_net(branch_inputs)\n\u001b[0;32m---> 47\u001b[0m trunk_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk_net(trunk_inputs)\n\u001b[1;32m     49\u001b[0m results \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mik, lk -> il\u001b[39m\u001b[38;5;124m'\u001b[39m, branch_outputs, trunk_outputs)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch4/sgoswam4/sharmila/02_Latent_DeepONet/paper_runs/Comparison_studies-2D_Stove_64x64_NEVALC/../../utils/networks.py:40\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlayers\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 40\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i](x))\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# no activation for last layer\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/modules/activation.py:393\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/.conda/envs/py311/lib/python3.11/site-packages/torch/nn/functional.py:2075\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   2074\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 2075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 79.14 GiB of which 820.75 MiB is free. Including non-PyTorch memory, this process has 78.33 GiB memory in use. Of the allocated memory 76.92 GiB is allocated by PyTorch, and 934.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "bs = 128 # Batch size\n",
    "\n",
    "neval_y = neval_x\n",
    "\n",
    "neval_c = {'t': neval_t, 'loc': neval_x*neval_y}  # Number of collocation points within the domain.\n",
    "        \n",
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20000, gamma=0.1) # gamma=0.8\n",
    "\n",
    "iteration_list, loss_list, learningrates_list = [], [], []\n",
    "datadriven_loss_list, pinn_loss_list = [], []\n",
    "test_iteration_list, test_loss_list = [], []\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    \n",
    "    if n_used == 0:\n",
    "        datadriven_loss = torch.tensor([0.]).to(device)\n",
    "        # print('*********')\n",
    "    else:\n",
    "        indices_datadriven = torch.randperm(n_used).to(device) # Generate random permutation of indices\n",
    "        inputs_train_used_batch = inputs_train_used.reshape(-1, 1, ny, nx)[indices_datadriven[0:bs]]\n",
    "        outputs_train_used_batch = outputs_train_used.reshape(-1, nt*nx*ny)[indices_datadriven[0:bs]]\n",
    "        # print(f\"Shape of inputs_train_used_batch:\", inputs_train_used_batch.shape) # (bs, no. of channels, height, width)\n",
    "        # print(f\"Shape of outputs_train_used_batch:\", outputs_train_used_batch.shape) # (bs, nt*nx*ny)\n",
    "\n",
    "        predicted_values = u_pred(model, inputs_train_used_batch, \n",
    "                              grid[:, 0].reshape(-1,1), \n",
    "                              grid[:, 1].reshape(-1,1), \n",
    "                              grid[:, 2].reshape(-1,1))  # (bs, neval) = (bs, nt*nx*ny)\n",
    "        target_values = outputs_train_used_batch # (bs, nt*nx*ny)\n",
    "        datadriven_loss = nn.MSELoss()(predicted_values, target_values)\n",
    "        # print('*********')\n",
    "    \n",
    "    num_samples = stove_source_fields_only['input_samples'].shape[0]\n",
    "    indices_pinn = torch.randperm(num_samples).to(device) # Generate random permutation of indices\n",
    "    input_parameters_batch = stove_source_fields_only['input_parameters'][indices_pinn[0:bs]]\n",
    "    inputs_batch = stove_source_fields_only['input_samples'].reshape(-1, 1, ny, nx)[indices_pinn[0:bs]]\n",
    "    # print(f\"Shape of inputs_batch:\", inputs_batch.shape) # (bs, no. of channels, height, width)\n",
    "\n",
    "    # points within the domain\n",
    "    tc_span = td.uniform.Uniform(0., T).sample((neval_c['t'], 1)).to(device)\n",
    "    xc_span = td.uniform.Uniform(-L, L).sample((neval_c['loc'], 1)).to(device)\n",
    "    yc_span = td.uniform.Uniform(-L, L).sample((neval_c['loc'], 1)).to(device)\n",
    "\n",
    "    tc, xc, yc = collocation_points(tc_span, xc_span, yc_span, neval_c)\n",
    "    pinn_loss = loss_pde_residual(model, input_parameters_batch, inputs_batch, tc, xc, yc)\n",
    "    # print('*********')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = datadriven_loss + pinn_loss\n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if iteration % 500 == 0:\n",
    "        # Test loss calculation\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            test_predicted_values = u_pred(model, inputs_test.reshape(-1, 1, ny, nx), \n",
    "                          grid[:, 0].reshape(-1,1), \n",
    "                          grid[:, 1].reshape(-1,1), \n",
    "                          grid[:, 2].reshape(-1,1))  # (bs, neval) = (bs, nt*nx*ny)\n",
    "            test_loss = nn.MSELoss()(test_predicted_values, outputs_test.reshape(-1, nt*nx*ny))\n",
    "            test_iteration_list.append(iteration)\n",
    "            test_loss_list.append(test_loss.item())  \n",
    "        model.train()  # Switch back to training mode\n",
    "        print('Iteration %s -' % iteration, 'loss = %f,' % loss,\n",
    "              'data-driven loss = %f,' % datadriven_loss,'pinn loss = %f,' % pinn_loss,\n",
    "              'learning rate = %f,' % optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "              'test loss = %f' % test_loss)\n",
    "\n",
    "    iteration_list.append(iteration)\n",
    "    loss_list.append(loss.item())\n",
    "    datadriven_loss_list.append(datadriven_loss.item())\n",
    "    pinn_loss_list.append(pinn_loss.item())\n",
    "    learningrates_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    free, total = torch.cuda.mem_get_info()\n",
    "    mem_used_MB = (total - free) / 1024 ** 2\n",
    "    print(f\"Memory used: {mem_used_MB:.2f} MB\")\n",
    "    \n",
    "if save == True:\n",
    "    np.save(os.path.join(resultdir,'iteration_list.npy'), np.asarray(iteration_list))\n",
    "    np.save(os.path.join(resultdir,'loss_list.npy'), np.asarray(loss_list))\n",
    "    np.save(os.path.join(resultdir, 'datadriven_loss_list.npy'), np.asarray(datadriven_loss_list))\n",
    "    np.save(os.path.join(resultdir, 'pinn_loss_list.npy'), np.asarray(pinn_loss_list))\n",
    "    np.save(os.path.join(resultdir,'learningrates_list.npy'), np.asarray(learningrates_list))\n",
    "    np.save(os.path.join(resultdir,'test_iteration_list.npy'), np.asarray(test_iteration_list))\n",
    "    np.save(os.path.join(resultdir, 'test_loss_list.npy'), np.asarray(test_loss_list)) \n",
    "\n",
    "plot_loss_terms(resultdir, iteration_list, loss_list, datadriven_loss_list, pinn_loss_list, save)  \n",
    "    \n",
    "plot_training_loss(resultdir, iteration_list, loss_list, save) \n",
    "\n",
    "plot_testing_loss(resultdir, test_iteration_list, test_loss_list, save)\n",
    "\n",
    "plot_training_testing_loss(resultdir, iteration_list, loss_list, test_iteration_list, test_loss_list, save)\n",
    "\n",
    "plot_learningrates(resultdir, iteration_list, learningrates_list, save)  \n",
    "    \n",
    "# end timer\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "runtime_per_iter = training_time/n_iterations # in sec/iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67807e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T10:54:51.182695Z",
     "iopub.status.busy": "2024-12-29T10:54:51.182280Z",
     "iopub.status.idle": "2024-12-29T10:54:51.189316Z",
     "shell.execute_reply": "2024-12-29T10:54:51.188988Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save == True:\n",
    "    torch.save(model.state_dict(), os.path.join(resultdir,'model_state_dict.pt'))\n",
    "# model.load_state_dict(torch.load(os.path.join(resultdir, 'model_state_dict.pt'), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521aff73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T10:54:51.204322Z",
     "iopub.status.busy": "2024-12-29T10:54:51.204179Z",
     "iopub.status.idle": "2024-12-29T11:00:21.869422Z",
     "shell.execute_reply": "2024-12-29T11:00:21.869085Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions_test = u_pred(model, inputs_test.reshape(-1, 1, ny, nx), \n",
    "                          grid[:, 0].reshape(-1,1), \n",
    "                          grid[:, 1].reshape(-1,1), \n",
    "                          grid[:, 2].reshape(-1,1))  # (bs, neval) = (bs, nt*nx*ny)\n",
    "# print(predictions_test.shape)\n",
    "\n",
    "mse_list, r2score_list, relerror_list = [], [], []\n",
    "    \n",
    "for i in range(inputs_test.shape[0]):\n",
    "    \n",
    "    prediction_i = predictions_test[i].reshape(1, -1) # (1, nt*nx*ny)\n",
    "    target_i = outputs_test[i].reshape(1, -1) # (1, nt*nx*ny)\n",
    "\n",
    "    mse_i = F.mse_loss(prediction_i.cpu(), target_i.cpu())\n",
    "    r2score_i = metrics.r2_score(target_i.flatten().cpu().detach().numpy(), prediction_i.flatten().cpu().detach().numpy()) \n",
    "    relerror_i = np.linalg.norm(target_i.flatten().cpu().detach().numpy() - prediction_i.flatten().cpu().detach().numpy()) / np.linalg.norm(target_i.flatten().cpu().detach().numpy())\n",
    "        \n",
    "    mse_list.append(mse_i.item())\n",
    "    r2score_list.append(r2score_i.item())\n",
    "    relerror_list.append(relerror_i.item())\n",
    "    \n",
    "    # Plot the full solution-field for few cases (2 groups i.e., 10*2=20):\n",
    "    if (i+1) <= 20:\n",
    "        print(colored('TEST SAMPLE '+str(i+1), 'red'))\n",
    "        shape = get_key_from_value(shape_map, input_parameters_test[i, 0])\n",
    "        print(colored(f\"Shape = {shape}, r = {input_parameters_test[i,2]:.3f}, a_value = {input_parameters_test[i,3]:.3f}\", 'red'))\n",
    "        \n",
    "        r2score_i = float('%.4f'%r2score_i)\n",
    "        relerror_i = float('%.4f'%relerror_i)\n",
    "        print('Rel. L2 Error = '+str(relerror_i)+', R2 score = '+str(r2score_i))\n",
    "        \n",
    "        # Plotting \n",
    "        plot_source(i, x_span, y_span, inputs_test[i], f\"{shape.capitalize()} Source\", 'hot', resultdir, save)\n",
    "        \n",
    "        cmap = 'hot'  # Color map\n",
    "        fontsize = 14  # Font size for labels and titles\n",
    "        levels = 100\n",
    "        plot_solution(i, x_span, y_span, target_i.reshape(nt,ny,nx), t_span, f\"True Solution for {shape.capitalize()} Source\", cmap, fontsize, levels, resultdir, save, 'True-Solution')\n",
    "        plot_solution(i, x_span, y_span, prediction_i.reshape(nt,ny,nx), t_span, f\"Predicted Solution for {shape.capitalize()} Source\", cmap, fontsize, levels, resultdir, save, 'Predicted-Solution')\n",
    "        plot_solution(i, x_span, y_span, torch.abs(target_i.reshape(nt,ny,nx) - prediction_i.reshape(nt,ny,nx)), t_span, f\"Absolute error for {shape.capitalize()} Source\", cmap, fontsize, levels, resultdir, save, 'Absolute error')\n",
    "        print(colored('#'*230, 'green'))\n",
    "\n",
    "mse = sum(mse_list) / len(mse_list)\n",
    "print(\"Mean Squared Error Test:\\n\", mse)\n",
    "r2score = sum(r2score_list) / len(r2score_list)\n",
    "print(\"R2 score Test:\\n\", r2score)\n",
    "relerror = sum(relerror_list) / len(relerror_list)\n",
    "print(\"Rel. L2 Error Test:\\n\", relerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac31ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T11:00:22.804712Z",
     "iopub.status.busy": "2024-12-29T11:00:22.804434Z",
     "iopub.status.idle": "2024-12-29T11:00:22.875170Z",
     "shell.execute_reply": "2024-12-29T11:00:22.874786Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    \"input_parameters_test\": input_parameters_test.cpu(),\n",
    "    \"inputs_test\": inputs_test.cpu(),\n",
    "    \"outputs_test\": outputs_test.cpu(),\n",
    "    \"predictions_test\": predictions_test.reshape(-1, nt, ny, nx).cpu()\n",
    "}\n",
    "for key, value in test_dict.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "print(colored('#'*230, 'green'))\n",
    "\n",
    "if save == True:\n",
    "    torch.save(test_dict, os.path.join(resultdir,'test_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965287e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-29T11:00:23.819800Z",
     "iopub.status.busy": "2024-12-29T11:00:23.819561Z",
     "iopub.status.idle": "2024-12-29T11:00:23.822384Z",
     "shell.execute_reply": "2024-12-29T11:00:23.822043Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_metrics(mse, r2score, relerror, training_time, runtime_per_iter, resultdir, save)\n",
    "# GPU memory used\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"Memory used (in MB):\\n{mem_used_MB:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9542a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcdbede",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.49493,
   "end_time": "2025-03-28T08:25:51.007446",
   "environment_variables": {},
   "exception": true,
   "input_path": "a_Vanilla-NO_ForwardADeinsum.ipynb",
   "output_path": "results/ForwardAD_neval_c/a_Vanilla-NO_ForwardADeinsum/output_neval_t=128_neval_x=128.ipynb",
   "parameters": {
    "neval_t": 128,
    "neval_x": 128
   },
   "start_time": "2025-03-28T08:25:38.512516",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
